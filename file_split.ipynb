{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as db\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = './data/orders/orders.parquet'\n",
    "output_directory = './data/orders/'\n",
    "rows_per_file = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Read the original Parquet file\n",
    "df = pd.read_parquet(input_file_path)\n",
    "\n",
    "# Calculate the number of splits needed\n",
    "total_rows = len(df)\n",
    "splits = total_rows // rows_per_file + (1 if total_rows % rows_per_file else 0)\n",
    "\n",
    "# Split and write to new Parquet files\n",
    "for i in range(splits):\n",
    "    start_row = i * rows_per_file\n",
    "    end_row = start_row + rows_per_file\n",
    "    df_subset = df.iloc[start_row:end_row]\n",
    "    output_file_path = os.path.join(output_directory, f'orders_{i+1}.parquet')\n",
    "    df_subset.to_parquet(output_file_path)\n",
    "\n",
    "print(f'Successfully split into {splits} files.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
